#!/usr/bin/env bash
set -euo pipefail
set -m                        # enable job control in non-interactive script (Git Bash)

POKEMON=(Bulbasaur Ivysaur Venusaur Charmander Charmeleon)
OUTDIR="pokemon_data_parallel"
ERR="errors.txt"
BASE="https://pokeapi.co/api/v2/pokemon"
mkdir -p "$OUTDIR"
: > "$ERR"

max_retries=3
base_sleep=1
max_parallel=3                # pool size — tune for API kindness

# On exit / Ctrl-C, kill background jobs so you don’t leave orphans
trap 'echo "Stopping..."; kill 0 2>/dev/null || true' SIGINT SIGTERM EXIT

fetch_with_retry() {
  local url="$1" out="$2"
  for attempt in $(seq 1 "$max_retries"); do
    http_code=$(curl -sS -w "%{http_code}" -o "$out.tmp" "$url") || http_code="000"
    if [[ "$http_code" == "200" ]]; then
      if jq -e '.name' "$out.tmp" >/dev/null 2>>"$ERR"; then
        mv "$out.tmp" "$out"; return 0
      else
        echo "[$(date -Is)] Invalid JSON from $url" >> "$ERR"
        rm -f "$out.tmp"; return 1
      fi
    fi
    if [[ "$http_code" == "429" || "$http_code" == 5* || "$http_code" == "000" ]]; then
      sleep_time=$(( base_sleep * 2 ** (attempt - 1) ))
      echo "[$(date -Is)] HTTP $http_code for $url. Retry in ${sleep_time}s (try $attempt/$max_retries)" >> "$ERR"
      sleep "$sleep_time"; continue
    fi
    echo "[$(date -Is)] Permanent error HTTP $http_code for $url" >> "$ERR"
    rm -f "$out.tmp"; return 1
  done
  echo "[$(date -Is)] Failed after $max_retries attempts: $url" >> "$ERR"
  rm -f "$out.tmp"; return 1
}

# Simple concurrency limiter
run_limited() {
  # jobs -r -p => only running jobs, print PIDs
  while (( $(jobs -r -p | wc -l) >= max_parallel )); do
    sleep 0.2
  done
  "$@" &   # launch in background
}

for p in "${POKEMON[@]}"; do
  p_lc="${p,,}"
  url="$BASE/$p_lc"
  out="$OUTDIR/${p_lc}.json"
  echo "Queueing fetch for ${p_lc}..."
  run_limited bash -c '
    url="$1"; out="$2"; name="$3"
    if fetch_with_retry "$url" "$out"; then
      echo "Saved data to $out ✅"
    else
      echo "Skipping ${name} due to repeated failures ❌"
    fi
  ' _ "$url" "$out" "$p_lc"
done

wait                      # block until all children complete
trap - EXIT               # clear trap so we don’t double-print “Stopping…”
echo "All parallel fetches completed."
